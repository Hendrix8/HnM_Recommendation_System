{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QfJxlQ28nZbO",
        "wupzsRHknZbS",
        "jsJK2WPonZbo",
        "g1BnfL1JAQen",
        "eGHzXsQjymUB",
        "in4MT-U-JQh3",
        "N1tLbWmlJTRv",
        "YglGt5dKMHon",
        "9uAohEfsyyNg",
        "ZmP2sUkLox7e",
        "ai3nlIJ5nZbo"
      ],
      "machine_shape": "hm",
      "gpuType": "V100"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Contents\n",
        "* [Load Sets](#load_sets)\n",
        "* [Handling NaN Values](#NaN_Values)\n",
        "* [Article Similarity with LSH](#ASwLSH)\n",
        "* [Creating the Final Datasets](#CFD)\n",
        "* [Saving the the dataframes for the models](#SDF)\n"
      ],
      "metadata": {
        "id": "AzW1jDtQnZbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"load_sets\"></a>\n",
        "## Load Sets"
      ],
      "metadata": {
        "id": "QfJxlQ28nZbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGLw-VlVr0c5",
        "outputId": "59a17525-9b65-4196-e085-64aec72a5b62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/Data/H&M_project/h-and-m-personalized-fashion-recommendations.zip\" # unzipping the data"
      ],
      "metadata": {
        "id": "B1VZpMrUryW8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# loading the datasets with pandas\n",
        "customers = pd.read_csv('/content/customers.csv')\n",
        "articles = pd.read_csv('/content/articles.csv')\n",
        "sample_sub = pd.read_csv('/content/sample_submission.csv')\n",
        "transactions_train = pd.read_csv('/content/transactions_train.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:02:09.853973Z",
          "iopub.execute_input": "2023-05-25T16:02:09.854772Z",
          "iopub.status.idle": "2023-05-25T16:03:37.111003Z",
          "shell.execute_reply.started": "2023-05-25T16:02:09.854720Z",
          "shell.execute_reply": "2023-05-25T16:03:37.109902Z"
        },
        "trusted": true,
        "id": "ynekgM9_nZbQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(transactions_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eun3T-rnBgLa",
        "outputId": "88770a01-ac32-45fe-86ec-9d65311b7ec9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31788324"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"NaN_Values\"></a>\n",
        "## Handling NaN Values"
      ],
      "metadata": {
        "id": "wupzsRHknZbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.120361Z",
          "iopub.execute_input": "2023-05-25T16:03:37.120779Z",
          "iopub.status.idle": "2023-05-25T16:03:37.146932Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.120747Z",
          "shell.execute_reply": "2023-05-25T16:03:37.145583Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iMlKzPNnZbS",
        "outputId": "154cb30c-6e12-424c-d52d-a276970d3ae3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id                    0\n",
              "FN                        895050\n",
              "Active                    907576\n",
              "club_member_status          6062\n",
              "fashion_news_frequency     16009\n",
              "age                        15861\n",
              "postal_code                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.149725Z",
          "iopub.execute_input": "2023-05-25T16:03:37.150075Z",
          "iopub.status.idle": "2023-05-25T16:03:37.166439Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.150045Z",
          "shell.execute_reply": "2023-05-25T16:03:37.165296Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG_KvLk1nZbT",
        "outputId": "0ba869f6-fec7-4d36-e1b2-e9fdc5b392a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article_id                        0\n",
              "product_code                      0\n",
              "prod_name                         0\n",
              "product_type_no                   0\n",
              "product_type_name                 0\n",
              "product_group_name                0\n",
              "graphical_appearance_no           0\n",
              "graphical_appearance_name         0\n",
              "colour_group_code                 0\n",
              "colour_group_name                 0\n",
              "perceived_colour_value_id         0\n",
              "perceived_colour_value_name       0\n",
              "perceived_colour_master_id        0\n",
              "perceived_colour_master_name      0\n",
              "department_no                     0\n",
              "department_name                   0\n",
              "index_code                        0\n",
              "index_name                        0\n",
              "index_group_no                    0\n",
              "index_group_name                  0\n",
              "section_no                        0\n",
              "section_name                      0\n",
              "garment_group_no                  0\n",
              "garment_group_name                0\n",
              "detail_desc                     416\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_train.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.167886Z",
          "iopub.execute_input": "2023-05-25T16:03:37.168267Z",
          "iopub.status.idle": "2023-05-25T16:03:37.178475Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.168228Z",
          "shell.execute_reply": "2023-05-25T16:03:37.177227Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD8Oubk9nZbU",
        "outputId": "2c0d9608-3d9a-4c2d-a997-983885f8115d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "t_dat               0\n",
              "customer_id         0\n",
              "article_id          0\n",
              "price               0\n",
              "sales_channel_id    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the transactions_train dataframe, column sales channel id, 2 is online and 1 store."
      ],
      "metadata": {
        "id": "H9wKGH6mnZbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The customers dataframe has the most NaN values. The articles dataframe only has 416 NaN values in the detail_desc column, these can be replaced with an empty string ''."
      ],
      "metadata": {
        "id": "Y5TKDVuhnZbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replacing the NaN values in detail_desc with an empty string\n",
        "articles['detail_desc'] = articles['detail_desc'].fillna('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.180002Z",
          "iopub.execute_input": "2023-05-25T16:03:37.181053Z",
          "iopub.status.idle": "2023-05-25T16:03:37.191789Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.181006Z",
          "shell.execute_reply": "2023-05-25T16:03:37.190237Z"
        },
        "trusted": true,
        "id": "LewE5fD5nZbV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the articles dataframe has no NaN values."
      ],
      "metadata": {
        "id": "-NjgyGQpnZbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "articles.isna().sum().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.193709Z",
          "iopub.execute_input": "2023-05-25T16:03:37.194241Z",
          "iopub.status.idle": "2023-05-25T16:03:37.215814Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.194191Z",
          "shell.execute_reply": "2023-05-25T16:03:37.214592Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF1P6TbynZbX",
        "outputId": "f836c1a7-6e06-4343-c2fb-9fcdd8e7fae2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the customers dataframe, FN is if a customer get Fashion News newsletter, Active is if the customer is active for communication. The problem is that there are to many NaN values for these two columns. Specifically FN : $ \\frac{895050}{1371980} 100 \\approx 65\\% $ and Active :  $ \\frac{907576}{1371980} 100 \\approx 66\\% $ So those columns will be dropped.\n"
      ],
      "metadata": {
        "id": "P19GeUpPnZbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the FN and Active columns\n",
        "customers = customers.drop(['FN', 'Active'], axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.217668Z",
          "iopub.execute_input": "2023-05-25T16:03:37.218244Z",
          "iopub.status.idle": "2023-05-25T16:03:37.352381Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.218209Z",
          "shell.execute_reply": "2023-05-25T16:03:37.350965Z"
        },
        "trusted": true,
        "id": "CtZ0GUOZnZbZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.353875Z",
          "iopub.execute_input": "2023-05-25T16:03:37.354259Z",
          "iopub.status.idle": "2023-05-25T16:03:37.370034Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.354226Z",
          "shell.execute_reply": "2023-05-25T16:03:37.368551Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox1mbwsfnZba",
        "outputId": "2216a06b-4e1a-462a-b502-72e1ef4039d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id                   0\n",
              "club_member_status         6062\n",
              "fashion_news_frequency    16009\n",
              "age                       15861\n",
              "postal_code                   0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First the columns will be factorized and then the mice imputing method will be applied to impute the nan values."
      ],
      "metadata": {
        "id": "Ac3Iio4LnZba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#\n",
        "df_mice = customers.drop(['customer_id'], axis=1).copy() # taking a copy of the customers dataset excluding the id\n",
        "\n",
        "df_mice['club_member_status'], cms_labels = pd.factorize(df_mice['club_member_status']) # factorizing all values of club_membership_status column\n",
        "df_mice['club_member_status'] = df_mice['club_member_status'].replace(-1, np.nan) # factorization gave the nan values the value -1, so here it is replaced back to nan\n",
        "\n",
        "df_mice['fashion_news_frequency'], fnf_labels = pd.factorize(df_mice['fashion_news_frequency']) # factorizing all values of fashion_news_frequency column\n",
        "df_mice['fashion_news_frequency'] = df_mice['fashion_news_frequency'].replace(-1, np.nan) # factorization gave the nan values the value -1, so here it is replaced back to nan\n",
        "\n",
        "df_mice['postal_code'], pc_labels = pd.factorize(df_mice['postal_code']) # factorizing all values of postal_code column\n",
        "\n",
        "df_mice.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.374655Z",
          "iopub.execute_input": "2023-05-25T16:03:37.375049Z",
          "iopub.status.idle": "2023-05-25T16:03:37.410968Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.375016Z",
          "shell.execute_reply": "2023-05-25T16:03:37.409886Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sWzNRX8LnZba",
        "outputId": "0917e62d-d63e-441b-b05c-68e91efacd51"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   club_member_status  fashion_news_frequency   age  postal_code\n",
              "0                 0.0                     0.0  49.0            0\n",
              "1                 0.0                     0.0  25.0            1\n",
              "2                 0.0                     0.0  24.0            2\n",
              "3                 0.0                     0.0  54.0            3\n",
              "4                 0.0                     1.0  52.0            4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e3bd6a6-4043-4132-83e5-a82c443ca892\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>club_member_status</th>\n",
              "      <th>fashion_news_frequency</th>\n",
              "      <th>age</th>\n",
              "      <th>postal_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e3bd6a6-4043-4132-83e5-a82c443ca892')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e3bd6a6-4043-4132-83e5-a82c443ca892 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e3bd6a6-4043-4132-83e5-a82c443ca892');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to impute the missing data using MICE"
      ],
      "metadata": {
        "id": "qWrHktpVnZbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Imputing with MICE\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn import linear_model\n",
        "\n",
        "# Define MICE Imputer and fill missing values\n",
        "mice_imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')\n",
        "\n",
        "df_mice_imputed = pd.DataFrame(mice_imputer.fit_transform(df_mice), columns=df_mice.columns)\n",
        "\n",
        "df_mice_imputed.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:37.412548Z",
          "iopub.execute_input": "2023-05-25T16:03:37.412901Z",
          "iopub.status.idle": "2023-05-25T16:03:39.301095Z",
          "shell.execute_reply.started": "2023-05-25T16:03:37.412871Z",
          "shell.execute_reply": "2023-05-25T16:03:39.299996Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2OwI0WxnZbb",
        "outputId": "4fa37e85-480f-4f0a-f119-6bb144360c66"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "club_member_status        0\n",
              "fashion_news_frequency    0\n",
              "age                       0\n",
              "postal_code               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the df_mice_imputed will be reverted back to it's original form\n"
      ],
      "metadata": {
        "id": "uSUYquZFnZbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mice_imputed['club_member_status'] = pd.Index(cms_labels)[df_mice_imputed['club_member_status'].to_numpy(dtype=int)]\n",
        "df_mice_imputed['fashion_news_frequency'] = pd.Index(fnf_labels)[df_mice_imputed['fashion_news_frequency'].to_numpy(dtype=int)]\n",
        "df_mice_imputed['postal_code'] = pd.Index(pc_labels)[df_mice_imputed['postal_code'].to_numpy(dtype=int)]\n",
        "\n",
        "df_mice_imputed.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:39.302599Z",
          "iopub.execute_input": "2023-05-25T16:03:39.303166Z",
          "iopub.status.idle": "2023-05-25T16:03:39.322045Z",
          "shell.execute_reply.started": "2023-05-25T16:03:39.303118Z",
          "shell.execute_reply": "2023-05-25T16:03:39.320833Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UK_x8qcnZbc",
        "outputId": "db3e1ffd-6d0c-44a8-c6ac-0818794217bc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "club_member_status        0\n",
              "fashion_news_frequency    0\n",
              "age                       0\n",
              "postal_code               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_mice_imputed.insert(0, 'customer_id', customers['customer_id'].to_numpy())\n",
        "df_mice_imputed.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:39.324003Z",
          "iopub.execute_input": "2023-05-25T16:03:39.324495Z",
          "iopub.status.idle": "2023-05-25T16:03:39.341154Z",
          "shell.execute_reply.started": "2023-05-25T16:03:39.324460Z",
          "shell.execute_reply": "2023-05-25T16:03:39.339975Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "F9KDUyxnnZbc",
        "outputId": "bf010a80-8d8e-41b3-db87-40ba6aa9c391"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         customer_id club_member_status  \\\n",
              "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...             ACTIVE   \n",
              "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...             ACTIVE   \n",
              "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...             ACTIVE   \n",
              "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...             ACTIVE   \n",
              "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...             ACTIVE   \n",
              "\n",
              "  fashion_news_frequency   age  \\\n",
              "0                   NONE  49.0   \n",
              "1                   NONE  25.0   \n",
              "2                   NONE  24.0   \n",
              "3                   NONE  54.0   \n",
              "4              Regularly  52.0   \n",
              "\n",
              "                                         postal_code  \n",
              "0  52043ee2162cf5aa7ee79974281641c6f11a68d276429a...  \n",
              "1  2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...  \n",
              "2  64f17e6a330a85798e4998f62d0930d14db8db1c054af6...  \n",
              "3  5d36574f52495e81f019b680c843c443bd343d5ca5b1c2...  \n",
              "4  25fa5ddee9aac01b35208d01736e57942317d756b32ddd...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-107e773b-76d8-4b02-9a90-73e035e99f4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>club_member_status</th>\n",
              "      <th>fashion_news_frequency</th>\n",
              "      <th>age</th>\n",
              "      <th>postal_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>49.0</td>\n",
              "      <td>52043ee2162cf5aa7ee79974281641c6f11a68d276429a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>64f17e6a330a85798e4998f62d0930d14db8db1c054af6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>54.0</td>\n",
              "      <td>5d36574f52495e81f019b680c843c443bd343d5ca5b1c2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>Regularly</td>\n",
              "      <td>52.0</td>\n",
              "      <td>25fa5ddee9aac01b35208d01736e57942317d756b32ddd...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-107e773b-76d8-4b02-9a90-73e035e99f4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-107e773b-76d8-4b02-9a90-73e035e99f4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-107e773b-76d8-4b02-9a90-73e035e99f4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers = df_mice_imputed.copy()\n",
        "customers.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:39.342695Z",
          "iopub.execute_input": "2023-05-25T16:03:39.343428Z",
          "iopub.status.idle": "2023-05-25T16:03:39.366098Z",
          "shell.execute_reply.started": "2023-05-25T16:03:39.343396Z",
          "shell.execute_reply": "2023-05-25T16:03:39.364970Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "XvuNWb-YnZbd",
        "outputId": "b9ae8735-ffd1-4a9b-aa7a-1dff6c12ea18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         customer_id club_member_status  \\\n",
              "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...             ACTIVE   \n",
              "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...             ACTIVE   \n",
              "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...             ACTIVE   \n",
              "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...             ACTIVE   \n",
              "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...             ACTIVE   \n",
              "\n",
              "  fashion_news_frequency   age  \\\n",
              "0                   NONE  49.0   \n",
              "1                   NONE  25.0   \n",
              "2                   NONE  24.0   \n",
              "3                   NONE  54.0   \n",
              "4              Regularly  52.0   \n",
              "\n",
              "                                         postal_code  \n",
              "0  52043ee2162cf5aa7ee79974281641c6f11a68d276429a...  \n",
              "1  2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...  \n",
              "2  64f17e6a330a85798e4998f62d0930d14db8db1c054af6...  \n",
              "3  5d36574f52495e81f019b680c843c443bd343d5ca5b1c2...  \n",
              "4  25fa5ddee9aac01b35208d01736e57942317d756b32ddd...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f710f27-5ebb-44a4-ba2d-79423a4419ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>club_member_status</th>\n",
              "      <th>fashion_news_frequency</th>\n",
              "      <th>age</th>\n",
              "      <th>postal_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>49.0</td>\n",
              "      <td>52043ee2162cf5aa7ee79974281641c6f11a68d276429a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>64f17e6a330a85798e4998f62d0930d14db8db1c054af6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>54.0</td>\n",
              "      <td>5d36574f52495e81f019b680c843c443bd343d5ca5b1c2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
              "      <td>ACTIVE</td>\n",
              "      <td>Regularly</td>\n",
              "      <td>52.0</td>\n",
              "      <td>25fa5ddee9aac01b35208d01736e57942317d756b32ddd...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f710f27-5ebb-44a4-ba2d-79423a4419ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f710f27-5ebb-44a4-ba2d-79423a4419ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f710f27-5ebb-44a4-ba2d-79423a4419ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-25T16:03:39.368075Z",
          "iopub.execute_input": "2023-05-25T16:03:39.369042Z",
          "iopub.status.idle": "2023-05-25T16:03:39.379797Z",
          "shell.execute_reply.started": "2023-05-25T16:03:39.369009Z",
          "shell.execute_reply": "2023-05-25T16:03:39.378553Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au721YqrnZbd",
        "outputId": "0ad7acf6-b3eb-4991-ca39-d6470a7653a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id               0\n",
              "club_member_status        0\n",
              "fashion_news_frequency    0\n",
              "age                       0\n",
              "postal_code               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"ASwKSH\"></a>\n",
        "## Article Similarity and Clustering using LSH"
      ],
      "metadata": {
        "id": "jsJK2WPonZbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### downloading datasketch"
      ],
      "metadata": {
        "id": "g1BnfL1JAQen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing the datasketch library for applying lsh\n",
        "!pip install datasketch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCv8DVDvJKy1",
        "outputId": "b68214aa-725a-4993-d480-5ee3b1579c15"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasketch\n",
            "  Downloading datasketch-1.5.9-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.10/dist-packages (from datasketch) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from datasketch) (1.10.1)\n",
            "Installing collected packages: datasketch\n",
            "Successfully installed datasketch-1.5.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing necesarry libraries"
      ],
      "metadata": {
        "id": "eGHzXsQjymUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries to process text\n",
        "import nltk\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fibZOfloykNs",
        "outputId": "c2de0144-40bc-4cfb-fa05-958377f002c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the text"
      ],
      "metadata": {
        "id": "in4MT-U-JQh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating some functions to help with processing our data\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  stop_words = set(stopwords.words('english')) # remove duplicates of stop words\n",
        "  text_tokens = nltk.word_tokenize(text) # tokenize the text\n",
        "  filtered_text = [word for word in text_tokens if word not in stop_words] # remove stop words\n",
        "  text = \" \".join(filtered_text) # rejoin text\n",
        "  return text\n",
        "\n",
        "def lemmatize(text):\n",
        "\n",
        "  tokens = nltk.word_tokenize(text) # tokenize the text\n",
        "  lemmatizer = WordNetLemmatizer() # create the lemmatizer object\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens] # lemmatize\n",
        "\n",
        "  # Join the lemmatized tokens back into a string\n",
        "  lem_text = \" \".join(lemmatized_tokens)\n",
        "\n",
        "  return lem_text"
      ],
      "metadata": {
        "id": "mOk3PHaIx5gX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(desc_list):\n",
        "\n",
        "  # processing the descriptions\n",
        "  processed_descriptions = []\n",
        "\n",
        "  # lowercasing the letters for every row of the description column\n",
        "  for desc in desc_list: # this is another way to get the column of your choice\n",
        "    desc = desc.lower() # applying the .lower method for each description\n",
        "    desc = re.sub(r'[^\\w\\s]', '', desc) # removig special characters, if there are any\n",
        "    desc = re.sub(r'\\d+', '', desc) # removing the numbers\n",
        "    desc = remove_stopwords(desc) # renove stop words\n",
        "    desc = lemmatize(desc) # lemmatize\n",
        "\n",
        "    processed_descriptions.append(desc)\n",
        "\n",
        "  return processed_descriptions\n",
        "\n",
        "item_desc = articles['detail_desc'] # store all descriptions of items\n",
        "articles['processed_desc'] = process(item_desc) # add processed descriptions to dataframe"
      ],
      "metadata": {
        "id": "MXb8N1o_zJ5q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### applying LSH with shinglings = words"
      ],
      "metadata": {
        "id": "N1tLbWmlJTRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasketch import MinHashLSHForest, MinHash\n",
        "import time\n",
        "\n",
        "\n",
        "# the set of descriptions for lsh\n",
        "descriptions = articles['processed_desc'].unique()\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# defining the number of permutations for the MinHash algorithm\n",
        "num_perm = 128\n",
        "\n",
        "# creating MinHash objects for each document\n",
        "minhashes = []\n",
        "for desc in descriptions:\n",
        "\n",
        "  # creating a MinHash object with the specified number of permutations\n",
        "  m = MinHash(num_perm=num_perm)\n",
        "\n",
        "  # iterating over each word in the document\n",
        "  for word in desc.split():\n",
        "\n",
        "    # updating the MinHash object with the encoded word\n",
        "    m.update(word.encode('utf-8'))\n",
        "\n",
        "  # adding the MinHash object to the list\n",
        "  minhashes.append(m)\n",
        "\n",
        "# creating an LSH forest and adding the MinHashes to it\n",
        "forest = MinHashLSHForest(num_perm=num_perm)\n",
        "\n",
        "for i, m in enumerate(minhashes):\n",
        "  # adding each MinHash object to the LSH forest, associating it with an index\n",
        "  forest.add(i, m)\n",
        "\n",
        "# indexing the forest to build the hash tables\n",
        "forest.index()\n",
        "\n",
        "\n",
        "# Calculate the training time\n",
        "lsh_time = time.time() - start_time\n",
        "\n",
        "print(f'LSH time : {lsh_time}')"
      ],
      "metadata": {
        "id": "xhX6gkc-ICMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b9a7dc-7bf4-491d-f3a3-7127df80d644"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSH time : 67.44848895072937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nearest neighbor clustering with LSH results"
      ],
      "metadata": {
        "id": "YglGt5dKMHon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_neighbors = 1000\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# going through every description\n",
        "# getting the minhash of the description\n",
        "# finding the similar n nearest descriptions and appending them to the list\n",
        "neighbors = [forest.query(minhashes[idx], n_neighbors)\n",
        "             for idx in tqdm(range(len(descriptions)), desc='Processing Neighbors')]\n",
        "\n",
        "\n",
        "# going through every description\n",
        "# iterating through the neighbors and adding them to the cluster\n",
        "clusters = []\n",
        "visited = set()\n",
        "for idx in tqdm(range(len(descriptions)), desc='Creaating Clusters'):\n",
        "    if idx not in visited:\n",
        "        cluster = [idx]\n",
        "        visited.add(idx)\n",
        "\n",
        "        for neighbor in neighbors[idx]:\n",
        "            if neighbor not in visited:\n",
        "                cluster.append(neighbor)\n",
        "                visited.add(neighbor)\n",
        "\n",
        "        clusters.append(cluster)\n",
        "\n",
        "# Calculate the training time\n",
        "cl_time = time.time() - start_time\n",
        "print()\n",
        "print(f'Cluster Creation Time : {cl_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7hWdfzpikhY",
        "outputId": "5f78385f-362e-4a9e-89ba-d41d6c7c4550"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Neighbors: 100%|██████████| 42657/42657 [02:37<00:00, 270.22it/s]\n",
            "Creaating Clusters: 100%|██████████| 42657/42657 [00:00<00:00, 495193.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Creation Time : 157.9632694721222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{len(clusters)} Clusters have been created')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaRng1hjoTz7",
        "outputId": "97de8b32-0605-4d5f-a47b-e24cd68ab3dd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304 Clusters have been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"CFD\"></a>\n",
        "## Creating the Final Datasets"
      ],
      "metadata": {
        "id": "67wSn7Gcpc6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding the 'class_label' to the articles dataframe"
      ],
      "metadata": {
        "id": "9uAohEfsyyNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article_id_clusters = []\n",
        "\n",
        "# iterating over all the clusters\n",
        "for cluster in clusters:\n",
        "\n",
        "  # extracting the descriptions of the cluster\n",
        "  cluster_descs = descriptions[cluster]\n",
        "\n",
        "  # taking the dataframe that contains these descriptions\n",
        "  cluster_articles = articles[articles['processed_desc'].isin(cluster_descs)]\n",
        "\n",
        "  # taking the id of those articles and adding it to article_id_clusters\n",
        "  article_id_clusters.append(cluster_articles['article_id'])\n"
      ],
      "metadata": {
        "id": "KyBlZ0SAyyNh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a column to add to articles as cluster classes\n",
        "cluster_classes = pd.DataFrame([i for i in range(len(articles))])\n",
        "\n",
        "class_label = 0\n",
        "for cluster in article_id_clusters:\n",
        "\n",
        "  # finding all the articles that belong to the cluster\n",
        "  cl = articles[articles['article_id'].isin(cluster)]\n",
        "\n",
        "  # assigning them their class label\n",
        "  cluster_classes.iloc[cl.index, 0] = class_label\n",
        "\n",
        "  class_label += 1\n"
      ],
      "metadata": {
        "id": "_trEmyNKyyNh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appending row to the articles dataframe\n",
        "articles['class_label'] = cluster_classes.to_numpy()"
      ],
      "metadata": {
        "id": "0Q3ppux_yyNh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving articles to use in the model notebook\n",
        "articles.to_pickle('articles.pkl', compression='gzip')"
      ],
      "metadata": {
        "id": "dukuPCUovye-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding class label to transactions_train dataframe"
      ],
      "metadata": {
        "id": "ZmP2sUkLox7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the cluster label of the article to the transactions_train dataset\n",
        "# creating a dictionary mapping article IDs to class labels\n",
        "article_class_map = dict(zip(articles['article_id'], articles['class_label']))\n",
        "\n",
        "# mapping the article IDs to class labels in transactions_train\n",
        "transactions_train['item_class'] = transactions_train['article_id'].map(article_class_map)\n"
      ],
      "metadata": {
        "id": "WJ4symL35I32"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting to train test and validation set"
      ],
      "metadata": {
        "id": "nTv28gR9JtOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "data = transactions_train.copy()\n",
        "\n",
        "# Converting the string column to datetime\n",
        "data['t_dat'] = pd.to_datetime(data['t_dat'])\n",
        "\n",
        "# Setting the date column as the index\n",
        "data.set_index('t_dat', inplace=True)"
      ],
      "metadata": {
        "id": "nvfyit8uLhg8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choosing how many days will the val and test be\n",
        "val_size = 30\n",
        "test_size = 7\n",
        "\n",
        "# splitting the data\n",
        "\n",
        "# Getting the first and last date\n",
        "last_date = data.index[-1]\n",
        "first_date = data.index[0]\n",
        "# calculating the test start date\n",
        "test_start_date = last_date - timedelta(days=test_size)\n",
        "\n",
        "# calculating the val start date\n",
        "val_start_date = test_start_date - timedelta(days=val_size)\n",
        "\n",
        "# get the transactions data for train, test and validation sets\n",
        "train_trans = data.loc[first_date: val_start_date]\n",
        "val_trans = data.loc[val_start_date: test_start_date]\n",
        "test_trans = data.loc[test_start_date: last_date]\n"
      ],
      "metadata": {
        "id": "P3PYHx_fMIIc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining the customer and transactions_train grouped by customer id for train val and test sets"
      ],
      "metadata": {
        "id": "Fz99nLmkpS_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function will help in creating the data for each transactions set\n",
        "def combine(transactions_data):\n",
        "\n",
        "  # grouping by customer\n",
        "  grouped_cust = transactions_data.groupby('customer_id').agg(lambda x: x.tolist())\n",
        "\n",
        "  # dropping duplicates of customer_id\n",
        "  customers_unique = customers.drop_duplicates(subset=['customer_id'])\n",
        "\n",
        "  # combining customers with the cluster classes label lists from what they bought\n",
        "  customers_fin = pd.merge(customers_unique, grouped_cust, on='customer_id', how='outer')\n",
        "\n",
        "  return customers_fin\n",
        "\n",
        "train = combine(train_trans)\n",
        "val = combine(val_trans)\n",
        "test = combine(test_trans)"
      ],
      "metadata": {
        "id": "JutdUaYlOvbw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clearing the nan values that were created in the combination process"
      ],
      "metadata": {
        "id": "86O7TkbRXQoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(inplace=True)\n",
        "val.dropna(inplace=True)\n",
        "test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "N8hH-ODDXCnb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining the customer and transactions_train grouped by customer id for the whole transactions_train (this will be used after we train and test the model in order to exploit all the data we have)"
      ],
      "metadata": {
        "id": "PR9dBYQGOEJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_all = combine(transactions_train)"
      ],
      "metadata": {
        "id": "zIEK4lcZ0kOg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_all.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZImR39Ue0xmh",
        "outputId": "4916f592-35cc-4f66-9e3f-1ad8e0bf9932"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id                  0\n",
              "club_member_status           0\n",
              "fashion_news_frequency       0\n",
              "age                          0\n",
              "postal_code                  0\n",
              "t_dat                     9699\n",
              "article_id                9699\n",
              "price                     9699\n",
              "sales_channel_id          9699\n",
              "item_class                9699\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From what is gathered above, it can be concluded that 9699 customers did not buy anything"
      ],
      "metadata": {
        "id": "Qm3vXDb5fD0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"#SDF\"></a>\n",
        "## Saving the dataframes for the model"
      ],
      "metadata": {
        "id": "KrdLoV9WxqjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_pickle('train.pkl', compression='gzip')\n",
        "val.to_pickle('val.pkl', compression='gzip')\n",
        "test.to_pickle('test.pkl', compression='gzip')\n",
        "train_all.to_pickle('train_all.pkl', compression='gzip')"
      ],
      "metadata": {
        "id": "NIe40swnx8Yc"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}